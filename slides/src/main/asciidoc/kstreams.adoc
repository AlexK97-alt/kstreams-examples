= Kafka Streams API: Шаг за рамки Hello World
Иван Пономарёв, КУРС/МФТИ
:revealjs_theme: black
:revealjs_customtheme: white_course.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false

//== Часть 1. Введение
:!figure-caption:

== Зачем нам Kafka?

[%step]
* Web-scraping в реальном времени
* 500 запросов/сек
* Удобные абстракции «из коробки»:
** «Подрезаемый» лог
** Batching
** Балансировка
* DISCLAIMER: пока не в production

== Kafka за 30 секунд
.Источник: Kafka. The Definitive Guide
image::kafka_cluster.png[{image-60-width}]

== Kafka Message

image::1024px-Aiga_mail.svg.png[{image-10-width}]

* Partition Number -- определяется Producer-ом
* Ключ
* Значение

== Compacted topics
.Источник: Kafka Documentation
image::log_compaction.png[{image-70-width}]

== Kafka Streams API: нам обещают...

[%step]
* Real-time stream processing
* Stream-like API (map / reduce)
* Под капотом:
** Автоматический коммит оффсетов
** Ребалансировка
** Внутреннее состояние обработчиков
** Interactive Queries


== Масштабирование? Легко!

* Параллелизация с автоматической ребалансировкой

.Источник: Kafka Documentation
image::streams-elastic-scaling-2.png[{image-50-width}]

== Попробуем?

image::gamov.png[{image-40-width}]

== Kafka Streams API: общая структура KStreams-приложения


[source,java]
----
StreamsConfig config = ...;
//Здесь устанавливаем всякие опции

StreamsBuilder builder = ...; 
//Здесь строим топологию


//Это за нас делает SPRING-KAFKA
KafkaStreams streams = new KafkaStreams(builder, config); 
streams.start(); 
...
streams.close();

----

== Топология

.Источник: Kafka Documentation
image::streams-architecture-topology.jpg[{image-40-width}]

== С чего начать?

image::initializr.png[{image-90-width}]


== @Bean KafkaConfiguration 

[source,java]
----
//ВАЖНО!
@Bean(name = 
    KafkaStreamsDefaultConfiguration
                .DEFAULT_STREAMS_CONFIG_BEAN_NAME)
public KafkaStreamsConfiguration getStreamsConfig() {
    Map<String, Object> props = new HashMap<>();
    //ВАЖНО!
    props.put(StreamsConfig.APPLICATION_ID_CONFIG, "my-app");
    //ВАЖНО!
    props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 4);
    props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    ...
    KafkaStreamsConfiguration streamsConfig = 
            new KafkaStreamsConfiguration(props);
    return streamsConfig;
}
----

== @Bean NewTopic

[source,java]
----
@Bean
NewTopic getFilteredTopic() {
    Map<String, String> props = new HashMap<>();
    props.put(
      TopicConfig.CLEANUP_POLICY_CONFIG,
      TopicConfig.CLEANUP_POLICY_COMPACT);
    return new NewTopic("mytopic", 10, (short) 1).configs(props);
}
----


== @Bean Topology
[graphviz, "yelling-topology.png"]
-----
digraph G {

rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="1.1"];

Source -> MapValues -> Sink

}
-----
{nbsp} +
[source,java]
----
@Bean
public Topology createTopology(StreamsBuilder streamsBuilder) {

    KStream<String, String> foo = streamsBuilder
        .stream("foo",Consumed.with(Serdes.String(), Serdes.String()))
        .mapValues((ValueMapper<String, String>) String::toUpperCase)
        .to("bar", Produced.with(Serdes.String(), Serdes.String()));
        return streamsBuilder.build();
}
----


== TopologyTestDriver: создание

[source,java]
----
KafkaStreamsConfiguration config = new KafkaConfiguration()
                                        .getStreamsConfig();
StreamsBuilder sb = new StreamsBuilder();
Topology topology = new TopologyConfiguration().createTopology(sb);
TopologyTestDriver topologyTestDriver = 
        new TopologyTestDriver(topology, 
                               config.asProperties());
----

== TopologyTestDriver: использование

[source,java]
----
ConsumerRecordFactory<String, String> factory = new
                ConsumerRecordFactory<>(...);
topologyTestDriver.pipeInput(factory.create("foo", "hello", "world"));

ProducerRecord<String, String> bar = 
    topologyTestDriver.readOutput("bar", ...);

assertEquals("hello", bar.key());
assertEquals("WORLD", bar.value());
----

== Демо

* Real-time processing
* Сохранение consumer offset

== Простое ветвление стримов
* Java-стримы так не могут:
[source,java]
----
KStream<..> foo = ...
KStream<..> bar = foo.mapValues(…).map... to...
Kstream<..> baz = foo.filter(…).map... forEach...
----
[graphviz, "simplebranch.png"]
-----
digraph G {
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.5"; label=""];
Start, BF, CF, DF [style="invis"]
Start -> A
A -> B -> BF
A -> C -> CF
}
-----

== Ветвление стримов по условию

* Не используйте KStream.branch, используйте KafkaStreamsBrancher!
[source,java]
----
new KafkaStreamsBrancher<String, String>()
   .branch((key, value) -> value.contains("A"), ks -> ks.to("A"))
   .branch((key, value) -> value.contains("B"), ks -> ks.to("B"))
   .defaultBranch(ks -> ks.to("C"))
   .onTopOf(builder.stream("source"))
   .map(...)
----
[graphviz, "switchbranch.png"]
-----
digraph G {
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.5"; label=""];
Start, BF, CF, DF [style="invis"]
Branch [shape="diamond", label="?"]
Start -> A -> Branch
Branch -> B -> BF
Branch -> C -> CF
}
-----

== Простое слияние
[source,java]
----
KStream<String, Integer> foo = ... 
KStream<String, Integer> bar = ...
KStream<String, Integer> merge = foo.merge(bar);
----
[graphviz, "merge.png"]
-----
digraph G {
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.5"; label=""];
Finish, BF, CF, DF [style="invis"]
BF -> A
CF -> B 
A -> C -> Finish
B -> C 
}
-----

== Локальное состояние

Facebook's RocksDB -- что это и зачем?

[.custom-style]
[cols="30a,70a"]
|===
.<|image::rocksdb.png[]
.<|
* Embedded key/value storage
* LSM Tree (Log-Structured Merge-Tree)
* High-performant (data locality)
* Persistent, optimized for SSD
|===


== RocksDB: краткий гид

* Сохранение K,V в бинарном формате
* Лексикографическая сортировка
* Iterator (snapshot view)
* Удаление диапазона (deleteRange)

== Пишем “Tweet Counting App”

* Подсчитаем твиты с хэштегом
* Key: имя пользователя, value: Count
* `KeyValueStore` и `Transformer`

== @Bean Topology
[graphviz, "counting-topology.png"]
-----
digraph G {
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> Filter -> Counter -> Sink
Counter -> Store [dir=both; label=" \n "]
{rank = same; Store; Counter;}
}
-----
{nbsp} +
[source,java]
----
KStream<String, String> filtered = streamsBuilder
            .stream("in")
            .filter((k, v) -> v.toLowerCase().contains("jpoint"));

KStream<String, Integer> counted =
    new CountingTransformer()
        .transformStream(streamsBuilder, filtered);
----


== Демо: Ребалансировка / репликация

* Ребалансировка / репликация партиций state при запуске / выключении обработчиков.

== Сохранение локального состояния в{nbsp}топик

[source,code]
----
$kafka-topics --describe counting-demo-app-jpoint-counted-changelog
Topic:counting-demo-app-jpoint-counted-changelog
PartitionCount:10       
ReplicationFactor:1 
Configs:cleanup.policy=compact
----

== Партиционирование и local state

image::streams-architecture-states.jpg[{image-70-width}]

== Репартиционирование
[graphviz, "through.png"]
-----
digraph G
{
    rankdir="LR";
    node [shape=record, width=.1, height=.1];
    node1 [label="{ | | | | }", fontsize = 18, xlabel= "through(. . .)"];
    
    node [label = " "; shape="circle"; fixedsize="true"; width="1.1"];
    Source -> node1
    node1 -> Sink
    
}
-----
{nbsp} +

* Явное при помощи +
`through(String topic, Produced<K, V> produced)`
* Неявное при `map()`/`selectKey()` и stateful-операциях

== Таблицы vs стримы

Местонахождение пользователя

.Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
image::stream-table-animation-latestLocation.gif[{image-100-width}]

== Таблицы vs стримы

Количество посещенных мест

.Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
image::stream-table-animation-numVisitedLocations.gif[{image-100-width}]


== Таблицы vs стримы

Производная и интеграл

.Martin Kleppmann, “Designing Data Intensive Applications”
image::derivative-and-integral.png[{image-100-width}]


== Переписываем counting app при помощи KTable

[source,java]
----
KTable<String, Long> count = filtered.groupByKey().count();

count.toStream().foreach((k, v) -> {
            gui.update(k, String.valueOf(v));
        });
----

[source,code]
----
$kafka-topics --describe
Topic:table-demo-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog 
PartitionCount:10
ReplicationFactor:1
Configs:cleanup.policy=compact
----


== Извлекаем самый свежий твит пользователя про #jpoint

[source,java]
----
KTable<String, String> latest = filtered.groupByKey()
            .reduce((v1, v2) -> v2);
latest.toStream()....
----
[source,code]
----
$kafka-topics --describe
Topic:table-demo-KSTREAM-REDUCE-STATE-STORE-0000000002-changelog 
PartitionCount:10
ReplicationFactor:1
Configs:cleanup.policy=compact
----



== Join: объединяем источники


image::derivative.png[{image-60-width}]

== Join: объединяем источники
[graphviz, "join-storages.png"]
-----
digraph G {
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store1 [shape="cylinder"; label="Local Store 1"; fixedsize="true"; width="1.7"]
Store2 [shape="cylinder"; label="Local Store 2"; fixedsize="true"; width="1.7"]
Source1 -> Join
Source2 -> Join

Join -> Sink
Join -> Store1 [dir=both; label=" \n "]
Join -> Store2 [dir=both; label=" \n "]
Store1 -> Store2 [style=invis]
{rank = same; Store1; Join }
}
-----

== Демо: Объединяем твиты с геолокацией
[source,java]
----
KTable<String, String> geo = streamsBuilder
        .table("geo", ...);
KTable<String, String> joined = latest
    .join(geo, (v1, v2) -> String.format("%s: %s", v2, v1));
----

[source,code]
----
$kafka-topics --list
table-demo-KSTREAM-REDUCE-STATE-STORE-0000000002-changelog
table-demo-geo-STATE-STORE-0000000006-changelog
----
== Копартиционирование: без него работать не будет!

image::streams-architecture-states.jpg[{image-70-width}]

== Операции между стримами и таблицами: сводка

image::streams-stateful_operations.png[{image-70-width}]


== Сохранение Timestamped-значений в{nbsp}RocksDB

WindowKeySchema.java

[source,java]
----
static Bytes toStoreKeyBinary(final byte[] serializedKey,
                                  final long timestamp,
                                  final int seqnum) {
        final ByteBuffer buf = ByteBuffer.allocate(serializedKey.length
                                        + TIMESTAMP_SIZE 
                                        + SEQNUM_SIZE);
        buf.put(serializedKey);
        buf.putLong(timestamp);
        buf.putInt(seqnum);
        return Bytes.wrap(buf.array());
    }
----

== Быстрое извлечение

[graphviz, "timestamped-record.png"]
-----
digraph G
{
    node [shape=record, fontsize=18];
    node0 [label="..."];
    node1 [label="<f0> key|<f1> timestamp|<f2> seqnum"];
    node2 [label="..."];
    node0 -> node1;
    node0 -> node2;
}
-----


== Tumbling window

[source,java]
----
TimeWindowedKStream<String, String> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20)));
----
.Источник: Kafka Streams in Action
image::tumbling-window.png[{image-80-width}]

== Hopping Window
[source,java]
----
TimeWindowedKStream<String, String> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20))
                        .advanceBy(Duration.ofSeconds(10)));
----
.Источник: Kafka Streams in Action
image::hopping-window.png[{image-60-width}]

== Session Window
[source,java]
----
SessionWindowedKStream<String, String> windowed = 
    stream.groupByKey()
        .windowedBy(SessionWindows.with(Duration.ofMinutes(5)));
----
image::streams-session-windows-02.png[{image-60-width}]

== Оконные агрегации: демо
[source,java]
----
TimeWindowedKStream<String, String> windowed = filtered
    .groupByKey()
    .windowedBy(TimeWindows.of(Duration.ofSeconds(5)));
    
KTable<Windowed<String>, Long> count = windowed.count();
----
[source,code]
----
$kafka-topics --list
windows-demo-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog
----
== Windowed<K> Interface

* `K key()`
* `Window window()`
** `Instant startTime()`
** `Instant endTime()`


== Kafka Streams in Action

[.custom-style]
[cols="30a,70a"]
|===
|image::KSIA.jpg[]
|
* **William Bejeck**, + 
“Kafka Streams in Action”, November 2018
* Примеры кода для Kafka 1.0
|===

== Kafka: The Definitive Guide

[.custom-style]
[cols="30a,70a"]
|===
|image::kafka-the-definitive-guide.jpg[]
|
* Gwen Shapira, Neha Narkhede, Todd Palino
* September 2017
|===



== Другие источники

- https://docs.confluent.io/current/streams/developer-guide/index.html[docs.confluent.io: Streams Developer Guide]
- https://www.confluent.io/blog/stream-processing-part-1-tutorial-developing-streaming-applications[Getting Your Feet Wet with Stream Processing (Confluent tutorials)]
- Исходники!
** https://github.com/apache/kafka/
** https://github.com/spring-projects/spring-kafka

== Выводы

* Kafka StreamsAPI -- это большой мир
* Kafka StreamsAPI -- это удобная абстракция над «сырой» Кафкой
* Чтобы начать пользоваться, надо настроить мышление под потоковую обработку
* Технология переживает бурное развитие
** + живой community, есть шанс повлиять на процесс самому 
** - публичные интерфейсы изменяются очень быстро

== На этом всё!

* Посмотрите примеры на https://github.com/inponomarev/kstreams-examples
* Подпишитесь на твиттер @inponomarev
{nbsp} +

ponomarev@corchestra.ru
{nbsp} +
Спасибо!
