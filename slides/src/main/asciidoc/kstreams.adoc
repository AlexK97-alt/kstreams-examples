= Kafka Streams API: Шаг за рамки Hello World
Иван Пономарёв, КУРС/МФТИ
:revealjs_theme: black
:revealjs_customtheme: white_course.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900


//== Часть 1. Введение
:!figure-caption:

== Зачем нам Kafka?

[%step]
* Web-scraping в реальном времени
* 500 запросов/сек (да, это очень мало!)
* Удобные абстракции «из коробки»:
** Персистентный, но «подрезаемый» лог
** Microbatching

== Зачем нам Streams API?

[%step]
* Real-time stream processing
* Stream-like API (map / reduce)
* Под капотом:
** Автоматический offset commit
** Ребалансировка
** Внутреннее состояние обработчиков
** Легкое масштабирование

== Disclaimer

Наш Kafka Streams ещё не в production!

[.fragment]
[.custom-style]
[cols="30a,70a"]
|===
.^|image::koshelev.jpg[]
.^|

Вопросы про production?

*Григорий Кошелев:*

«Когда всё пошло по Кафке»
|===


== Kafka за 30 секунд
.Источник: Kafka. The Definitive Guide
image::kafka_cluster.png[{image-60-width}]

== Kafka Message

image::1024px-Aiga_mail.svg.png[{image-10-width}]

* Номер партиции
* Ключ
* Значение

== Compacted topics
.Источник: Kafka Documentation
image::log_compaction.png[{image-60-width}]

== Попробуем?

image::gamov.png[{image-40-width}]

[transition="fade-out, slide-in"]
== Kafka Streams API: общая структура KStreams-приложения

[source,java]
----
StreamsConfig config = ...;
//Здесь устанавливаем всякие опции

StreamsBuilder builder = ...; 
//Здесь строим топологию
----

[transition="fade-in, fade-out"]
== Kafka Streams API: общая структура KStreams-приложения
Топология -- конвейер обработчиков:

[graphviz,"topology-sample.png"]
----
digraph G {

graph [ dpi = 140 ];
rankdir="LR";
node [shape="circle" fontsize=14; fixedsize="true"; width="1.3" ];


a[label="source"];
b[label="source"];
c[label="branch /\nsplit"];

d[label="process"];
e[label="join /\nmerge"];
f[label="sink"];
g[label="sink"];
{rank = same; a; b;}
a->c;
b->e;
c->e;
c->d;
d->f;
e->g;

}
----


[transition="fade-in, slide-out"]
== Kafka Streams API: общая структура KStreams-приложения

[source,java]
----
StreamsConfig config = ...;
//Здесь устанавливаем всякие опции

StreamsBuilder builder = ...; 
//Здесь строим топологию


//Это за нас делает SPRING-KAFKA
KafkaStreams streams = new KafkaStreams(builder, config); 
streams.start(); 
...
streams.close();

----



== В Спринге достаточно определить две вещи

* `@Bean KafkaStreamsConfiguration`
* `@Bean Topology`

[.fragment]
[.custom-style]
[cols="30a,70a"]
|===
.^|image::borisov.png[]
.<|И не забудьте про `@EnableKafkaStreams`
|===

== Demo Time

== @Bean KafkaConfiguration 

[source,java]
----
//ВАЖНО!
@Bean(name = 
    KafkaStreamsDefaultConfiguration
                .DEFAULT_STREAMS_CONFIG_BEAN_NAME)
public KafkaStreamsConfiguration getStreamsConfig() {
    Map<String, Object> props = new HashMap<>();
    //ВАЖНО!
    props.put(StreamsConfig.APPLICATION_ID_CONFIG,
        "bet-totalling-demo-app");
    //ВАЖНО!
    props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 4);
    props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    ...
    KafkaStreamsConfiguration streamsConfig = 
            new KafkaStreamsConfiguration(props);
    return streamsConfig;
}
----

== @Bean NewTopic

[source,java]
----
@Bean
NewTopic getFilteredTopic() {
    Map<String, String> props = new HashMap<>();
    props.put(
      TopicConfig.CLEANUP_POLICY_CONFIG,
      TopicConfig.CLEANUP_POLICY_COMPACT);
    return new NewTopic("mytopic", 10, (short) 1).configs(props);
}
----


== @Bean Topology
[graphviz, "yelling-topology.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="1.1"];

Source -> MapVal -> Sink

}
-----

[source,java]
----
@Bean
public Topology createTopology(StreamsBuilder streamsBuilder) {

    KStream<String, String> foo = streamsBuilder
        .stream("foo",Consumed.with(Serdes.String(), Serdes.String()))
        .mapValues((ValueMapper<String, String>) String::toUpperCase)
        .to("bar", Produced.with(Serdes.String(), Serdes.String()));
        return streamsBuilder.build();
}
----


== TopologyTestDriver: создание

[source,java]
----
KafkaStreamsConfiguration config = new KafkaConfiguration()
                                        .getStreamsConfig();
StreamsBuilder sb = new StreamsBuilder();
Topology topology = new TopologyConfiguration().createTopology(sb);
TopologyTestDriver topologyTestDriver = 
        new TopologyTestDriver(topology, 
                               config.asProperties());
----

== TopologyTestDriver: использование

[source,java]
----
ConsumerRecordFactory<String, String> factory = new
                ConsumerRecordFactory<>(...);
topologyTestDriver.pipeInput(factory.create("foo", "hello",
                                                "world"));

ProducerRecord<String, String> bar = 
    topologyTestDriver.readOutput("bar", ...);

assertEquals("hello", bar.key());
assertEquals("WORLD", bar.value());
----

== Простое ветвление стримов
Java-стримы так не могут:
[source,java]
----
KStream<..> foo = ...
KStream<..> bar = foo.mapValues(…).map... to...
Kstream<..> baz = foo.filter(…).map... forEach...
----
[graphviz, "simplebranch.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.5"; label=""];
Start, BF, CF, DF [style="invis"]
Start -> A
A -> B -> BF
A -> C -> CF
}
-----

== Ветвление стримов по условию

Не используйте `KStream.branch`, используйте `KafkaStreamsBrancher`!
[source,java]
----
new KafkaStreamsBrancher<String, String>()
   .branch((key, value) -> value.contains("A"), ks -> ks.to("A"))
   .branch((key, value) -> value.contains("B"), ks -> ks.to("B"))
   .defaultBranch(ks -> ks.to("C"))
   .onTopOf(builder.stream("source"))
   .map(...)
----
[graphviz, "switchbranch.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.5"; label=""];
Start, BF, CF, DF [style="invis"]
Branch [shape="diamond", label="?"]
Start -> A -> Branch
Branch -> B -> BF
Branch -> C -> CF
}
-----

== Простое слияние
[source,java]
----
KStream<String, Integer> foo = ... 
KStream<String, Integer> bar = ...
KStream<String, Integer> merge = foo.merge(bar);
----
[graphviz, "merge.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.5"; label=""];
Finish, BF, CF, DF [style="invis"]
BF -> A
CF -> B 
A -> C -> Finish
B -> C 
}
-----

== Локальное состояние

Facebook's RocksDB -- что это и зачем?

[.custom-style]
[cols="30a,70a"]
|===
.^|image::rocksdb.png[]
.^|
* Embedded key/value storage
* LSM Tree (Log-Structured Merge-Tree)
* High-performant (data locality)
* Persistent, optimized for SSD
|===


== RocksDB похож на `TreeMap<K,V>`

* Сохранение K,V в бинарном формате
* Лексикографическая сортировка
* Iterator (snapshot view)
* Удаление диапазона (deleteRange)

== Пишем “Bet Totalling App”

[cols="30a,70a"]
|===
.^|image::soccerball.png[]
.^|
* Идут футбольные матчи (меняется счёт)
* Делаются ставки: H, D, A.
* Ключ составной: `Cyprus-Belgium:A`
* Значение:
[source,java]
----
final String bettor;
final String match;
final Outcome outcome; //H, D or A
final long amount;
final long timestamp;
----
* Какова сумма ставок на исход?
|===

== Demo Time

== @Bean Topology
[graphviz, "counting-topology.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
}
-----

[source,java]
----
KStream<String, Bet> input = streamsBuilder.
    stream(BET_TOPIC, Consumed.with(Serdes.String(),
                      new JsonSerde<>(Bet.class)));

KStream<String, Long> counted =
    new TotallingTransformer()
        .transformStream(streamsBuilder, input);
----

== Суммирование ставок
[source,java]
----
@Override
public KeyValue<String, Long> transform(String key, Bet value,
                    KeyValueStore<String, Long> stateStore) {
    long current = Optional
        .ofNullable(stateStore.get(key))
        .orElse(0L);
    current += value.getAmount();
    stateStore.put(key, current);
    return KeyValue.pair(key, current);
}
----

== StateStore доступен в тестах
[source,java]
----
@Test
void testTopology() {
    topologyTestDriver.pipeInput(...);
    topologyTestDriver.pipeInput(...);

    KeyValueStore<String, Long> store =
        topologyTestDriver
        .getKeyValueStore(TotallingTransformer.STORE_NAME);
    
    assertEquals(..., store.get(...));
    assertEquals(..., store.get(...));
}
----


== Демо: Ребалансировка / репликация

* Ребалансировка / репликация партиций state при запуске / выключении обработчиков.

== Сохранение локального состояния в{nbsp}топик

[source,code]
----
$kafka-topics --zookeeper localhost --describe

Topic:bet-totalling-demo-app-totalling-store-changelog
PartitionCount:10       
ReplicationFactor:1 
Configs:cleanup.policy=compact
----

== Партиционирование и local state

[graphviz, "local-partitioning.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {

     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source"];
          S2 [shape=plaintext label = "Local store"];
          S3 [shape=plaintext label = "Changelog"];
          S1->S2->S3 [style="invis"]
      }

    subgraph cluster_p1 {
      label = "Worker 1";
        
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
 
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
        
        ls1[shape="cylinder" label = "RocksDB"]
        a->ls1;
        b->ls1;
        c->ls1;
        
        p1[shape="plaintext" label = "Partition 1"];
        p2[shape="plaintext" label = "Partition 2"];
        ls1->p1[dir="both"];
        ls1->p2[dir="both"];
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          
          
        ls2[shape="cylinder" label = "RocksDB"]
        d->ls2;
        p3[shape="plaintext" label = "Partition 3"];
        ls2->p3[dir="both"];
    }
    
    
  }
} 
-----

== Репартиционирование
[graphviz, "through.png"]
-----
digraph G
{
    graph [ dpi = 150 ]; 
    rankdir="LR";
    node [shape=record, width=.1, height=.1];
    node1 [label="{ | | | | }", fontsize = 18, xlabel= "through(. . .)"];
    
    node [label = " "; shape="circle"; fixedsize="true"; width="1.1"];
    Source -> node1
    node1 -> Sink
    
}
-----

* Явное при помощи +
`through(String topic, Produced<K, V> produced)`
* Неявное при `map()`/`selectKey()` и stateful-операциях

== Таблицы vs стримы

Местонахождение пользователя

.Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
image::stream-table-animation-latestLocation.gif[{image-100-width}]

== Таблицы vs стримы

Количество посещенных мест

.Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
image::stream-table-animation-numVisitedLocations.gif[{image-100-width}]


== Таблицы vs стримы

Производная и интеграл

.Martin Kleppmann, “Designing Data Intensive Applications”
image::derivative-and-integral.png[{image-100-width}]


== Переписываем totalling app при помощи KTable

[source,java]
----
KTable<String, Long> totals = input.groupByKey()
    .aggregate(
        () -> 0L, 
        (k, v, a) -> a + v.getAmount(),
        //Неявное создание локального хранилища
        Materialized.with(Serdes.String(), Serdes.Long())
    );
----

[source,code]
----
$kafka-topics --zookeeper localhost --describe

Topic: 
table2-demo-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog 
PartitionCount:10
ReplicationFactor:1
Configs:cleanup.policy=compact
----


== Получаем таблицу счетов матчей

[source,java]
----
KStream<String, Score> scores = 
    eventScores.flatMap((k, v) ->
        Stream.of(Outcome.H, Outcome.A).map(o ->
            KeyValue.pair(String.format("%s:%s", k, o), v))
            .collect(Collectors.toList()))
    .mapValues(EventScore::getScore);

KTable<String, Score> tableScores =
    scores.groupByKey(Grouped.with(...).reduce((a, b) -> b);

----
[source,code]
----
$kafka-topics --zookeeper localhost --list

table2-demo-KSTREAM-REDUCE-STATE-STORE-0000000006-repartition
table2-demo-KSTREAM-REDUCE-STATE-STORE-0000000006-changelog
----



== Join: объединяем источники

image::derivative.png[{image-40-width}]

[graphviz, "join-storages.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store1 [shape="cylinder"; label="Local Store 1"; fixedsize="true"; width="1.7"]
Store2 [shape="cylinder"; label="Local Store 2"; fixedsize="true"; width="1.7"]
Source1 -> Join
Source2 -> Join

Join -> Sink
Join -> Store1 [dir=both; label=" \n "]
Join -> Store2 [dir=both; label=" \n "]
Store1 -> Store2 [style=invis]
{rank = same; Store1; Join }
}
-----

== Демо: Объединяем сумму ставок с текущим счётом
[source,java]
----
KTable<String, String> joined = 
    totals.join(tableScores,
            (total, eventScore) -> 
                String.format("(%s)\t%d", eventScore, total));
----


[transition="fade-out, slide-in"]
== Копартиционирование

Join работает


[graphviz, "copart-norm.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
          subgraph cluster_pp12{
              label = "Partition 2"
              labelloc ="b"
          
              b1 [label = "B"];
              
              c1[label = "C"];
          }
          
          subgraph cluster_p1{
              label = "Partition 1"
          labelloc = "b"
              
              a1 [label = "A"]
              
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          c->c1[style="dashed" dir="none"];
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          subgraph cluster_p2{
              label = "Partition 3"
              labelloc = "b"
              d1[label = "D"];
              
              
          }
          
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

[transition="fade-in, fade-out"]
== Несовпадение количества партиций

Join не работает (Runtime Exception)

[graphviz, "copart-diff.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = "Partition 1"
              labelloc = "b"
              b1 [label = "B"]
              a1 [label = "A"]
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
              
              a [label = "A"];
              
          }
          
          subgraph cluster_pa2{
              label = "Partition 2"
          b [label = "B"];
              c [label = "C" color="red"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
          
              d[label = "D"];
              
              
          }
          subgraph cluster_pa3{
              label = "Partition 2"
              labelloc = "b"
          
              d1[label = "D"];
              c1[label = "C" color ="red"];
              
          }
          c->c1[ dir="none" color="red"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

[transition="fade-in, slide-out"]
== Несовпадение алгоритма партицирования

Join не работает молча!

[graphviz, "copart-diff-algorithm.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = "Partition 1"
              labelloc = "b"
          
              b1 [label = "B" color="red"]
              a1 [label = "A"]
              
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
               c[label = "C" color= "red"];
              a [label = "A"];
              
          }
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 2"
          b [label = "B" color="red"];
              d[label = "D"];
             
              
          }
          subgraph cluster_p2{
              label = "Partition 2"
              labelloc = "b"
              d1[label = "D"];
              c1[label = "C" color = "red"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[color="red" dir="none"];
          c->c1[color="red" dir="none"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== GlobalKTable

Реплицируется всюду целиком

[source,java]
----
GlobalKTable<...> global = streamsBuilder.globalTable("global", ...);
----

[graphviz, "globalktable.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "GlobalKTable"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = ""
          
              b1 [label = "B"]
              a1 [label = "A"]
              cc [label = "C"] 
              dd [label = "D"]
              a1->cc[style="invis"];
              b1->dd[style="invis"];
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
             
              a [label = "A"];
              b [label = "B"];
          }
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 2"
                c[label = "C"];
              
              d[label = "D"];
              
             
              
          }
          subgraph cluster_p2{
              label = ""
              labelloc = "b"
              d1[label = "D"];
              c1[label = "C" ];
              aa[label = "A"];
              bbb[label = "B"];
              c1->aa [style= "invis"];
              d1->bbb [style= "invis"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          c->c1[style="dashed" dir="none"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== Операции между стримами и таблицами: сводка
.Источник: https://kafka.apache.org/20/documentation/streams/developer-guide/dsl-api.html#stateful-transformations[Kafka Streams DSL Documentation]
image::streams-stateful_operations.png[{image-50-width}]


== Время, вперёд!

[source,java]
----
KStream<String, Bet> bets = streamsBuilder.stream(BET_TOPIC,
    Consumed.with(
            Serdes...)
            .withTimestampExtractor(
                
                (record, previousTimestamp) ->
                    ((Bet) record.value()).getTimestamp()

            ));
----
(Ещё время можно извлечь из WallClock и RecordMetadata.)

== Сохранение Timestamped-значений в{nbsp}RocksDB

WindowKeySchema.java

[source,java]
----
static Bytes toStoreKeyBinary(byte[] serializedKey,
                              long timestamp,
                              int seqnum) {
    ByteBuffer buf = ByteBuffer.allocate(
                                serializedKey.length
                                + TIMESTAMP_SIZE 
                                + SEQNUM_SIZE);
    buf.put(serializedKey);
    buf.putLong(timestamp);
    buf.putInt(seqnum);
    return Bytes.wrap(buf.array());
}
----

== Быстрое извлечение значений по ключу из диапазона времени

[graphviz, "timestamped-record.png"]
-----
digraph G
{
    graph [ dpi = 150 ]; 
    node [shape=record, fontsize=18];
    node0 [label="..."];
    node1 [label="<f0> key|<f1> timestamp|<f2> seqnum"];
    node2 [label="..."];
    node0 -> node1;
    node0 -> node2;
}
-----


== Tumbling window

[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20)));
----
.Источник: Kafka Streams in Action
image::tumbling-window.png[{image-70-width}]

== Tumbling window
[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20)));
    
KTable<Windowed<String>, Long> count = windowed.count();
----

`Windowed<K>` interface:

* `K key()`
* `Window window()`
** `Instant startTime()`
** `Instant endTime()`

== Hopping Window
[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20))
                        .advanceBy(Duration.ofSeconds(10)));
----
.Источник: Kafka Streams in Action
image::hopping-window.png[{image-50-width}]

== Session Window
[source,java]
----
SessionWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(SessionWindows.with(Duration.ofMinutes(5)));
----
image::streams-session-windows-02.png[{image-50-width}]


== Демо: Windowed Joins

* «Послегольщик» — игрок, пытающийся протолкнуть правильную ставку в момент смены счёта в матче
* Штамп времени ставки и события смены счёта должны «почти совпадать».

== Демо: Windowed Joins
По событию смены счёта понимаем, какая ставка будет «правильной»:
[source,java]
----
public KeyValue<String, Bet> transform(String key, 
                    EventScore value, 
                    KeyValueStore<String, Score> stateStore) {
        Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
        stateStore.put(key, value.getScore());
        Outcome currenOutcome = 
                value.getScore().getHome() > current.getHome() 
                ?
                Outcome.H : Outcome.A;
        Bet bestBet = new Bet(null, 
                            value.getEvent(), 
                            currenOutcome, 
                            0, 
                            value.getTimestamp());
        return KeyValue.pair(String.format("%s:%s", key, currenOutcome), bestBet);

}
----

== Демо: Windowed Joins
[source, java]
----
KStream<String, String> join = bets.join(outcomes,
    (bet, sureBet) -> 
    
    String.format("%s %dms before goal", 
                bet.getBettor(),
                sureBet.getTimestamp() - bet.getTimestamp()),
                JoinWindows.of(Duration.ofSeconds(1)).before(Duration.ZERO),
                Joined.with(Serdes....
    ));
----

== Kafka Streams in Action

[.custom-style]
[cols="30a,70a"]
|===
|image::KSIA.jpg[]
|
* **William Bejeck**, + 
“Kafka Streams in Action”, November 2018
* Примеры кода для Kafka 1.0
|===

== Kafka: The Definitive Guide

[.custom-style]
[cols="30a,70a"]
|===
|image::kafka-the-definitive-guide.jpg[]
|
* Gwen Shapira, Neha Narkhede, Todd Palino
* September 2017
|===



== Другие источники

- https://docs.confluent.io/current/streams/developer-guide/index.html[docs.confluent.io: Streams Developer Guide]
- https://www.confluent.io/blog/stream-processing-part-1-tutorial-developing-streaming-applications[Getting Your Feet Wet with Stream Processing (Confluent tutorials)]
- Исходники!
** https://github.com/apache/kafka/
** https://github.com/spring-projects/spring-kafka
- Телеграм: Грефневая Кафка
** https://t.me/AwesomeKafka_ru
** https://t.me/proKafka

== Выводы

[%step]
* Kafka StreamsAPI -- это удобная абстракция над «сырой» Кафкой
* Чтобы начать пользоваться, надо настроить мышление под потоковую обработку
* Технология переживает бурное развитие
** + живой community, есть шанс повлиять на процесс самому 
** - публичные интерфейсы изменяются очень быстро

== На этом всё!

* https://github.com/inponomarev/kstreams-examples

* Мой твиттер @inponomarev

* Мой email: ponomarev@corchestra.ru

* *Спасибо!*
